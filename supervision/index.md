---
layout: single
classes: wide
author_profile: true
title: "Supervision"
---

## Open Position
### Internship
I'm always open to accepting internships with highly motivated students. If you are interested please send me your CV and a short motivation letter.

### Student Research Assistant (HiWi):
One hiwi position with XAI focus: https://www.linkedin.com/feed/update/urn:li:activity:7234074023708553217/ 

## Open topics

If you are interested in any topics mentioned below, please send me your CV and a short motivation letter.

### 1. ToolFormer integration in conversational XAI systems
As LLMs is getting more and more complex, the need for explaining black box model is growing. However, sometimes one-off explanations are not sufficient, e.g., due to ambiguity. Thus, we introduced interactive conversational XAI systems, which can provide multiple explainability methods in a dialogue manner. The code can be reused from below referenced papers (https://github.com/DFKI-NLP/InterroLang), which can also give you an overview how such systems look like. The goal of this thesis is: try to integrate Toolformer into conversation XAI systems. When a specific explainability method is called by the user, the user question should be annotated by some certain patterns, with help of which corresponding tools should be invoked.

References: <a href="https://aclanthology.org/2023.findings-emnlp.359/">Feldhus et al. (2023)</a>; <a href="https://aclanthology.org/2024.hcinlp-1.9/">Wang et al. (2024)</a>; <a href="https://openreview.net/pdf?id=Yacmpz84TH">Schick et al. (2023)</a>

### 2. Development of new approaches for generating alteractuals
One of popular explainability method is called counterfactual, which refers to the edited input whose prediction after edition is different than that before edition. However, alterfactual is kind of the opposition, which refers to altered version and the prediction does not change. Since alterfactual generation is less explored by the NLP communities, the goal of the thesis is to create a new approach to generate alterfactual.

References: <a href="https://arxiv.org/pdf/2405.05295">Mertes et al. (2024)</a>;  <a href="https://www.arxiv.org/pdf/2408.10528">Nguyen et al. (2024)</a>
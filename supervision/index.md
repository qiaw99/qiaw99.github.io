---
layout: single
classes: wide
author_profile: true
title: "Supervision"
---

## Thesis Supervision
### Ongoing
- [Jiaao Li](https://github.com/grayJiaaoLi) (with [Nils Feldhus](https://nfelnlp.github.io/)) - Master Thesis - Title: _Code Verification of Thought: Natural Language Explanation Generation through Code Completion_

[//]: # (### Completed)

## Student Research Assistant Supervision
### Ongoing
- [Yoana Tsoneva](https://github.com/ytsoneva24) (2025/01/16-): multilingual intent recognition in conversational XAI systems

## Open Topics
If you are interested in any topics mentioned below, please send me your CV, transcript of record, and a short motivation letter.

[//]: # (### 1. ToolFormer integration in conversational XAI systems)

[//]: # (As LLMs is getting more and more complex, the need for explaining black box model is growing. However, sometimes one-off explanations are not sufficient, e.g., due to ambiguity. Thus, we introduced interactive conversational XAI systems, which can provide multiple explainability methods in a dialogue manner. The code can be reused from below referenced papers &#40;https://github.com/DFKI-NLP/InterroLang&#41;, which can also give you an overview how such systems look like. The goal of this thesis is: try to integrate Toolformer into conversation XAI systems. When a specific explainability method is called by the user, the user question should be annotated by some certain patterns, with help of which corresponding tools should be invoked.)

[//]: # ()
[//]: # (References: <a href="https://aclanthology.org/2023.findings-emnlp.359/">Feldhus et al. &#40;2023&#41;</a>; <a href="https://aclanthology.org/2024.hcinlp-1.9/">Wang et al. &#40;2024&#41;</a>; <a href="https://openreview.net/pdf?id=Yacmpz84TH">Schick et al. &#40;2023&#41;</a>)

### 1. Development of new approaches for generating alteractuals
One of popular explainability method is called counterfactual, which refers to the edited input whose prediction after edition is different than that before edition. However, alterfactual is kind of the opposition, which refers to altered version and the prediction does not change. Since alterfactual generation is less explored by the NLP communities, the goal of the thesis is to create a new approach to generate alterfactual.

References: <a href="https://arxiv.org/pdf/2405.05295">Mertes et al. (2024)</a>;  <a href="https://www.arxiv.org/pdf/2408.10528">Nguyen et al. (2024)</a>

### 2. Refining and Aligning Natural Language Explanations through Human-Guided Feedback
References: [Li et al. (2022)](https://aclanthology.org/2022.findings-acl.75/); [Hong et al. (2024)](https://aclanthology.org/2024.emnlp-main.626/); [Chen et al. (2024)](https://arxiv.org/abs/2412.08393)
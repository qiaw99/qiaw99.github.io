---
layout: single
classes: wide
author_profile: true
title: "Publications"
---
(* denotes equal contribution)

## 2026

### Paper2Figure: Evaluating Automated Schematic Figure Generation and Assessment for Scientific Papers
Shengyun Si, Jing Yang, Vera Schmitt, Yang Wang, Zihang Wang, **Qianli Wang**, Jiaao Li, Guanyi Liu, Sebastian M√∂ller, Arman Cohan, Yilun Zhao <br>
_In submission_<br>

## 2025
<img src="https://raw.githubusercontent.com/qiaw99/qiaw99.github.io/main/figures/compass.png?raw=true" width="60px" align="right">

### Multilingual Datasets for Custom Input Extraction and Explanation Requests Parsing in Conversational XAI Systems
**Qianli Wang**, Tatiana Anikina, Nils Feldhus, Simon Ostermann, Fedor Splitt, Jiaao Li, Yoana Tsoneva, Sebastian M√∂ller, Vera Schmitt <br>
<img src="https://img.shields.io/badge/EMNLP Findings-2025-blue"><br>
[ACL Anthology](https://aclanthology.org/2025.findings-emnlp.29/) | [arXiv](http://arxiv.org/abs/2508.14982) | [GitHub](https://github.com/qiaw99/compass)

### Truth or Twist? Optimal Model Selection for Reliable Label Flipping Evaluation in LLM-based Counterfactuals
**Qianli Wang**, Van Bach Nguyen, Nils Feldhus, Luis Felipe Villa-Arenas, Christin Seifert, Sebastian M√∂ller, Vera Schmitt<br>
<span><img src="https://img.shields.io/badge/INLG-2025-blue"><span style="color:red">(Oral Presentation)</span></span><br>
[ACL Anthology](https://aclanthology.org/2025.inlg.5/) | [arXiv](https://arxiv.org/abs/2505.13972) | [GitHub](https://github.com/qiaw99/failure)

<img src="https://raw.githubusercontent.com/qiaw99/qiaw99.github.io/main/figures/quantization.png?raw=true" width="80px" align="right">

### üîçThrough a Compressed Lens: Investigating The Impact of Quantization on Factual Knowledge Recall
**Qianli Wang**, Mingyang Wang, Nils Feldhus, Simon Ostermann, Yuan Cao, Hinrich Sch√ºtze, Sebastian M√∂ller, Vera Schmitt <br>
_In submission_<br>
[arXiv](https://arxiv.org/abs/2505.13963) | _(Code will be publicly available once the paper is published)_


### Beyond Transparency: Evaluating Explainability in AI-Supported Fact-Checking
Vera Schmitt, Isabel Bezzaoui, Charlott Jakob, Premtim Sahitaj, **Qianli Wang**, Arthur Hilbert, Max Upravitelev, Jonas Fegert, Sebastian M√∂ller, Veronika Solopova <br>
_ICMR 2025 Workshop on Multimedia AI against Disinformation_ <br>
[ACM Proceeding](https://dl.acm.org/doi/full/10.1145/3733567.3735566)

<img src="https://raw.githubusercontent.com/qiaw99/qiaw99.github.io/main/figures/fitcf_logo.png?raw=true" width="125px" align="right">

### FitCF: A Framework for Automatic Feature Importance-guided Counterfactual Example Generation
**Qianli Wang**, Nils Feldhus, Simon Ostermann, Luis Felipe Villa-Arenas, Sebastian M√∂ller, Vera Schmitt <br>
<img src="https://img.shields.io/badge/ACL Findings-2025-blue"><br>
[ACL Anthology](https://aclanthology.org/2025.findings-acl.64/) | [arXiv](https://arxiv.org/abs/2501.00777) | [GitHub](https://github.com/qiaw99/FitCF)

### Cross-Refine: Improving Natural Language Explanation Generation by Learning in Tandem
**Qianli Wang**, Tatiana Anikina, Nils Feldhus, Simon Ostermann, Sebastian M√∂ller, and Vera Schmitt<br>
*<img src="https://img.shields.io/badge/COLING-2025-blue">*<br>
[ACL Anthology](https://aclanthology.org/2025.coling-main.77/) | [arXiv](https://arxiv.org/abs/2409.07123) | [GitHub](https://github.com/qiaw99/Cross-Refine)

## 2024
### AnchorAlign: Self-Explanations Enhancement via Anchored Alignment
Luis Felipe Villa-Arenas, Ata Nizamoglu, **Qianli Wang**, Sebastian M√∂ller, and Vera Schmitt<br>
*In submission*<br>
[arXiv](https://arxiv.org/abs/2410.13216) | [GitHub](https://github.com/felipevillaarenas/anchored-alignment)

### CoXQL: A Dataset for Explanation Request Parsing in Conversational XAI Systems
**Qianli Wang**, Tatiana Anikina, Nils Feldhus, Simon Ostermann, and Sebastian M√∂ller <br>
*<img src="https://img.shields.io/badge/EMNLP Findings-2024-blue">*  <br>
[ACL Anthology](https://aclanthology.org/2024.findings-emnlp.76/) | [arXiv](https://arxiv.org/abs/2406.08101) | [GitHub](https://github.com/DFKI-NLP/CoXQL)  

<img src="https://raw.githubusercontent.com/qiaw99/qiaw99.github.io/main/figures/InstruX_Logo.png?raw=true" width="125px" align="right"> 

### Towards Modeling and Evaluating Instructional Explanations in Teacher-Student Dialogues
Nils Feldhus, Aliki Anagnostopoulou, **Qianli Wang**, Milad Alshomary, Henning Wachsmuth, Daniel Sonntag, and Sebastian M√∂ller  
*ACM GoodIT 2024 (Work in Progress track)*  
[ACM Digital Library](https://dl.acm.org/doi/10.1145/3677525.3678665) | [OpenReview (previous version submitted to ARR)](https://openreview.net/forum?id=mHgNzfiApQ)


<img src="https://raw.githubusercontent.com/qiaw99/qiaw99.github.io/main/figures/LLMCheckup_Logo.png?raw=true" width="125px" align="right"> 

### LLMCheckup: Conversational Examination of Large Language Models via Interpretability Tools and Self-Explanations
**Qianli Wang**, Tatiana Anikina, Nils Feldhus, Josef van Genabith, Leonhard Hennig, and Sebastian M√∂ller  
*NAACL 2024 Workshop on Bridging Human-Computer Interaction and Natural Language Processing (HCI+NLP)*  
[ACL Anthology](https://aclanthology.org/2024.hcinlp-1.9) | [arXiv](https://arxiv.org/abs/2401.12576) | [GitHub](https://github.com/DFKI-NLP/LLMCheckup)  



## 2023

<a href="https://aclanthology.org/2023.findings-emnlp.359/"><img src="https://raw.githubusercontent.com/nfelnlp/nfelnlp.github.io/main/figures/InterroLang_Logo.png?raw=true" width="150px" align="right"></a>  
### InterroLang: Exploring NLP Models and Datasets through Dialogue-based Explanations
Nils Feldhus, **Qianli Wang**, Tatiana Anikina, Sahil Chopra, Cennet Oguz, and Sebastian M√∂ller  
<img src="https://img.shields.io/badge/EMNLP Findings-2023-blue"> & *[BlackboxNLP](https://blackboxnlp.github.io/) Workshop*  
[ACL Anthology](https://aclanthology.org/2023.findings-emnlp.359/) | [arXiv](https://arxiv.org/abs/2310.05592) | [GitHub](https://github.com/DFKI-NLP/InterroLang)  

